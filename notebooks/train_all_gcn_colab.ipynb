{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GNN Training - All Datasets with Normalization\n",
        "\n",
        "**Configuration:**\n",
        "- Datasets: Cora, PubMed, Roman-empire, Minesweeper\n",
        "- Model: GCN with `normalize=True` (self-loops enabled)\n",
        "- K values: 0-8\n",
        "- Seeds: 0-3\n",
        "- **Total: 144 models**\n",
        "\n",
        "**Estimated runtime on A100:** 30-60 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (optimized for Colab)\n",
        "import torch\n",
        "print(f'Pre-installed PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.version.cuda}')\n",
        "\n",
        "# Install PyTorch Geometric (auto-detects PyTorch version)\n",
        "import sys\n",
        "!{sys.executable} -m pip install -q torch-geometric\n",
        "\n",
        "# Install PyG extensions without pyg-lib (not needed for GCN)\n",
        "!{sys.executable} -m pip install -q torch-scatter torch-sparse --no-index --find-links https://data.pyg.org/whl/torch-2.5.0+cu128.html\n",
        "\n",
        "# Install other dependencies\n",
        "!{sys.executable} -m pip install -q scikit-learn pandas matplotlib seaborn\n",
        "\n",
        "print('\\n\u2713 All dependencies installed')\n",
        "\n",
        "# Verify PyG installation\n",
        "import torch_geometric\n",
        "print(f'PyTorch Geometric: {torch_geometric.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f'GPU available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU name: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Navigate to project directory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Check current directory and find project root\n",
        "print(f'Starting directory: {os.getcwd()}')\n",
        "!ls -la\n",
        "\n",
        "# Try common Colab sync locations\n",
        "possible_paths = [\n",
        "    '/content/entropy-selection',\n",
        "    '/content',\n",
        "    os.getcwd(),  # Current directory\n",
        "]\n",
        "\n",
        "project_dir = None\n",
        "for path in possible_paths:\n",
        "    src_path = os.path.join(path, 'src')\n",
        "    if os.path.exists(src_path) and os.path.isdir(src_path):\n",
        "        project_dir = path\n",
        "        break\n",
        "\n",
        "if project_dir:\n",
        "    os.chdir(project_dir)\n",
        "    print(f'\\n\u2713 Found project at: {project_dir}')\n",
        "    print(f'Current directory: {os.getcwd()}')\n",
        "    print(f'\\nSource modules:')\n",
        "    !ls src/\n",
        "else:\n",
        "    print('\\n\u274c ERROR: Could not find src/ directory')\n",
        "    print('Available files in current directory:')\n",
        "    !ls -la\n",
        "    raise FileNotFoundError('Project src/ directory not found. Files may not have synced from local.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Triple Training Pipeline\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "\n",
        "datasets = ['Cora', 'PubMed', 'Roman-empire', 'Minesweeper']\n",
        "K_values = list(range(9))  # 0-8\n",
        "seeds = [0, 1, 2, 3]\n",
        "\n",
        "total_runs = len(datasets) * len(K_values) * len(seeds) * 3  # x3 for 3 pipelines\n",
        "print(f'Total training runs: {total_runs} (3 pipelines x {len(datasets)} datasets x {len(K_values)} K values x {len(seeds)} seeds)')\n",
        "print(f'Pipelines: 1) Standard GNN, 2) Exponential classifier heads, 3) Class-weighted classifier heads\\n')\n",
        "\n",
        "current = 0\n",
        "start_time = datetime.now()\n",
        "\n",
        "for dataset in datasets:\n",
        "    for K in K_values:\n",
        "        for seed in seeds:\n",
        "            current += 1\n",
        "            print(f'\\n{\"=\"*60}')\n",
        "            print(f'[{current}/{total_runs}] {dataset} | K={K} | seed={seed}')\n",
        "            print(f'{\"=\"*60}')\n",
        "            \n",
        "            # Pipeline 1: Standard GNN training\n",
        "            print(f'\\n[1/3] Training standard GNN...')\n",
        "            cmd = f'python -m src.train_gnn --dataset {dataset} --model GCN --K {K} --seed {seed}'\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=False)\n",
        "            if result.returncode != 0:\n",
        "                print(f'\u274c Failed: {cmd}')\n",
        "                continue\n",
        "            \n",
        "            # Pipeline 2: Exponential classifier heads\n",
        "            current += 1\n",
        "            print(f'\\n[{current}/{total_runs}] [2/3] Training exponential classifier heads...')\n",
        "            cmd = f'python -m src.train_gnn_classifier_heads --dataset {dataset} --model GCN --K {K} --seed {seed} --loss-type exponential --beta 0.5'\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=False)\n",
        "            if result.returncode != 0:\n",
        "                print(f'\u274c Failed: {cmd}')\n",
        "            \n",
        "            # Pipeline 3: Class-weighted classifier heads\n",
        "            current += 1\n",
        "            print(f'\\n[{current}/{total_runs}] [3/3] Training class-weighted classifier heads...')\n",
        "            cmd = f'python -m src.train_gnn_classifier_heads --dataset {dataset} --model GCN --K {K} --seed {seed} --loss-type class-weighted --beta 0.5'\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=False)\n",
        "            if result.returncode != 0:\n",
        "                print(f'\u274c Failed: {cmd}')\n",
        "            \n",
        "            # Progress update\n",
        "            elapsed = (datetime.now() - start_time).total_seconds() / 60\n",
        "            avg_time_per_triple = elapsed / (current / 3)\n",
        "            remaining = (total_runs / 3 - current / 3) * avg_time_per_triple\n",
        "            print(f'\\n\u23f1  Elapsed: {elapsed:.1f}min | Est. remaining: {remaining:.1f}min')\n",
        "\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print(f'\u2713 ALL TRAINING COMPLETE!')\n",
        "total_time = (datetime.now() - start_time).total_seconds() / 60\n",
        "print(f'Total time: {total_time:.1f} minutes')\n",
        "print(f'{\"=\"*60}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training complete!\n",
        "print('\u2713 Training complete!')\n",
        "print('Results saved in results/runs/')\n",
        "print('\\nNext steps (run locally):')\n",
        "print('1. Extract embeddings')\n",
        "print('2. Run probing')\n",
        "print('3. Generate plots')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}